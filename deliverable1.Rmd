---
title: "Discovery and Data Preperation"
author: "Austin Meyer"
date: "10/10/2019"
output: html_document
---

# Introduction

### Hello

  Hello my name is Austin Meyer. For my Data Science course at CSU Chico I wanted to investigate data from the United States about the economy and politics. I chose this area because, it interests me and is everywhere in our daily lives.

### Chosen Data Set

  The dataset has been acquired from [FiveThirtyEight]("https://projects.fivethirtyeight.com/2018-midterm-election-forecast/house/#history") an ABC company. By the looks of their data they have a left tilt when looking for data to investigate. How I justified this assumption is based on how many political data sets they started working with from their inseption in 2014 up to 2016. Then how many political data sets they started working with after the election of 2016. The data set I found is polling data, which means only people who want to take the poll have been recorded. With that in mind lets move on to some clearifications in the data.
  
### What Do These Columns Mean

  Some of the columns in this data may be confusing, at least some were to me. The columns that make up most of the confusion are the p10_voteshare and p90_voteshare. I looked it up and found a pretty good article that explanes it better than I can: [What do p10 and p90 mean]("https://blogs.dnvgl.com/software/2016/12/p10-p50-and-p90/"). In the case of our data a p10 voteshare means that 10% of the vote share will exceed x (x being the number). A p90 discribes that 90% of the voteshare will exceed this value.
  
  * Forcast date is when the election was supposed to take place, which has already happened.
  
  * State is straight forward. It is the state in which the canadite was running.
  
  * District is also straight forward. This is the district in which the canadite was running in a certian state.
  
  * The special elections column will be TRUE if a special election happend that election.


# Getting Started With Data Cleaning

### Download packages

  First we will download necessary packages to recreate the data sets I will have and be investigating. We will be first installing the wonderful tidyverse. The tidyverse package will help us bring order too messed up data.
```{r}
# These three will import many of the commands we will use to clean our data
# install.packages("tidyverse")
library("tidyverse")
library("tidyr")
# Will help us in manipulating our datasets
library("dplyr")
# Helps us read files from the web
library("readr")
# This library will help us visualize the data
library("ggplot2")
```


### Loading The Data

  Finally we get to load the data into our Rstudio set up. If you don't already have R and Rstudio please follow these two links and follow their download processes:
  * [R download (The langauge library)]("https://cran.r-project.org/mirrors.html")
    + Don't be afraid of all the links, just scroll down to one nearest to you
  *[Rstudio download]("https://rstudio.com/products/rstudio/download/#download")
  
  Now were ready to move on to downloading the data.The line bellow will turn the data into R readable data.
```{r}
national_data <- read_csv("https://projects.fivethirtyeight.com/congress-model-2018/house_district_forecast.csv")
```

Looking over the data there are a few things we need to clean up. One of those is to make sure the time is in POSIX time, which is just a standardized way of writing time.Luckly the date is already in the form we desire.


We also need to remove the models column. It is used specifically for the website that the data was pulled from. We will do this by selecting everything, but the model column.
```{r}
national_data <- select (national_data,-c(model))
```

# Early Assessment and Visualization

  The first questions I had when looking at this data is: What were the probable vote shares of incumbent canadites. First I had to create a new table that was filled with just the incubents.
```{r}
incumbent_chances <- tibble(candidate=national_data$candidate[national_data$incumbent == TRUE], win_probability=national_data$win_probability[national_data$incumbent == TRUE], voteshare=national_data$voteshare[national_data$incumbent == TRUE])
```

  Next we will make a histograph, which shows use were the voteshares fall for the incumbents.
```{r}
filter(national_data, (incumbent == TRUE)) %>% ggplot(aes(voteshare)) + geom_histogram(bins = 100)
```

  This graph tells us a lot about the probability of incumbents faired in the last election. Many of them had above 50% of the vote shares. The real question though is what keeps them in office. Is it a lack of a better candidate or are they representinng their districts well.

  The next graph we will look at the non-incumbents. Since the probability of the incumbents is above fifty, the non-incumbent probability will be the latter half of that.
```{r}
filter(national_data, (incumbent == FALSE)) %>% ggplot(aes(voteshare)) + geom_histogram(bins = 100)
```

As we expected the non-incumbents voteshare is below the 50% mark. Most of the non-incumbants had below a 10% predicted rate of winning any races.

# The Question

Now to lay out the questions I will be seeking to answer in my reaserch:

* As a nation, why do we continue to vote in the same politicians. 
* What qualities or events cause non-incumbents to have a low probability of winning. 
* Being a midterm election, how much did the president's actions influence was the president in the elections.

## And the Adventure Begins

  The data that I have chosen is just a launch pad for our investigation into our elections and why we vote the way we do.